{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Author: Jun Ding\n",
    "# Email: junding (at) cs (dot) cmu (dot) edu\n",
    "# Date: June. 29th, 2020\n",
    "# \n",
    "# This scdiff software suite is desinged to infer the clusters, trajectories, and regulatory\n",
    "# networks underlying dynamic biological process (e.g., cell differntiation, disease progression)\n",
    "# based on given time-series single-cell expression input data.  Please use \"scdiff -h\" for the detailed usage.\n",
    "# \n",
    "# This software is freely avaible for academic uses. \n",
    "# For any commerical usage, please contact me at the email address above.\n",
    "# All rights reserved.\n",
    "# Please don NOT modify the above statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scikit_learn-0.21.3-py3.6-linux-x86_64.egg/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pdb,sys,os,random\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import argparse\n",
    "import functools\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from File import * \n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import pkg_resources\n",
    "from viz2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Class Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cell\n",
    "class Cell:\n",
    "    def __init__(self, Cell_ID, TimePoint, Expression,typeLabel):\n",
    "        self.ID=Cell_ID\n",
    "        self.T=TimePoint\n",
    "        self.E=Expression\n",
    "        self.Label=None # Label for clustering purpose\n",
    "        self.typeLabel=typeLabel\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Class Cluter (Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Cluster (Node in the Tree Graph-Trajectory)\n",
    "class Cluster:\n",
    "    def __init__(self,cells,ID):\n",
    "        self.cells=cells                                 # cells (data poitns) for the cluster\n",
    "        self.ID=ID                                       # ID\n",
    "        self.P=None                                      # parent cluster\n",
    "        self.C=[]                                        # child clusters\n",
    "        self.E=self.__getAvgEx()                           # initial mean expression\n",
    "        self.R=self.__getVariance()                        # initial observation variance\n",
    "        [self.mT,self.rT]=self.__getAvgVarT()              # initial mean,variance Time\n",
    "        self.T=self.mT                                   # Time \n",
    "        self.PR=0                                        # Prior probability of cluster\n",
    "            \n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    ## public functions:\n",
    "    \n",
    "    # calculate the total probability of a cell belonging to given cluster (based on expression, and time)\n",
    "    def getAssignProbability(self,cell,W,TW=1.0):\n",
    "        # public interface to calculate probability of cell assignment \n",
    "        # W: Gene weight\n",
    "        # TW: time weight\n",
    "        p1 = self.__getCellProbability(cell,W) \n",
    "        PG=np.mean(p1)\n",
    "        PT=math.log(TW)+norm.logpdf(cell.T,self.mT,self.rT)\n",
    "        PR = math.log(self.PR)\n",
    "        P=PG+PT+PR\n",
    "        return P\n",
    "    \n",
    "    # get expressed TFs of the cluster\n",
    "    def getExpressedTF(self,TFList,GL):\n",
    "        PTF=[]\n",
    "        EXCUT=0.85   # at least 1-EXCUT non-zero => expressed\n",
    "        HGL=[item.upper() for item in GL]\n",
    "        for i in TFList:\n",
    "            if i in HGL:\n",
    "                ix=HGL.index(i)\n",
    "                x=[item.E[0,ix] for item in self.cells]\n",
    "                x.sort()\n",
    "                if x[int(EXCUT*len(x))]>0:\n",
    "                    PTF.append(i)\n",
    "        return PTF\n",
    "    #----------------------------------------------------------------\n",
    "    ## private functions\n",
    "    # calculate the probability of a cell belonging to given cluster  based on the guassian distribution (expression)\n",
    "    def __getCellProbability(self,cell,W):\n",
    "        # priviate function, can't be accessed outside, can only be called by other functions of the class\n",
    "        # cell: a cell\n",
    "        # mu,sm\n",
    "        # return mean logpdf (log of the probability density function) => log joint density \n",
    "        mu=self.E\n",
    "        sm=self.R\n",
    "        \n",
    "        P=[]\n",
    "        for i in range(len(mu)):\n",
    "            p=math.log(W[i])+norm.logpdf(cell.E[0,i],mu[i],sm[i])\n",
    "            P.append(p)\n",
    "        return P\n",
    "    \n",
    "  \n",
    "    # get the mean,sigma- time of the cluster\n",
    "    def __getAvgVarT(self):\n",
    "        iT=[item.T for item in self.cells]\n",
    "        pCount=0.01\n",
    "        imu=round(np.mean(iT),2)\n",
    "        ivar=round(np.var(iT)+pCount,2)\n",
    "        return [imu,ivar]\n",
    "        \n",
    "    # get the mean expression of the cluster\n",
    "    def __getAvgEx(self):\n",
    "        L=self.cells[0].E.shape[1]\n",
    "        AE=[]\n",
    "        for i in range(L):\n",
    "            iE=[item.E[0,i] for item in self.cells]\n",
    "            AE.append(np.mean(iE))\n",
    "        return AE\n",
    "    \n",
    "    # get the variance of the cluster\n",
    "    def __getVariance(self,mu=None):\n",
    "        # get the variance of genes within this clusters\n",
    "        L=self.cells[0].E.shape[1]\n",
    "        R=[]\n",
    "        for i in range(L):\n",
    "            gi=[item.E[0,i] for item in self.cells]\n",
    "            if mu==None:\n",
    "                vi=getVarianceVector(gi)\n",
    "            else:\n",
    "                vi=getVarianceVector(gi,mu[i])\n",
    "            R.append(vi)\n",
    "        pcount=0.01\n",
    "        R=[item+pcount for item in R]\n",
    "        return R\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Class Path (Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Path (Edge)\n",
    "class Path:\n",
    "    def __init__(self,fromNode,toNode,Nodes,GL,dTD,dTG,dMb,fChangeCut=0.6):\n",
    "        self.fromNode=fromNode                                                  # from Node\n",
    "        self.toNode=toNode                                                      # to Node\n",
    "        self.AllNodes=Nodes\n",
    "        \n",
    "        self.FC=self.__getFC(GL)                                                      # fold change for all genes\n",
    "        self.diffF=self.__getDiffGene(fChangeCut)                                     # get differnetial genes based on log fold change \n",
    "        self.diffT=self.__getDiffGeneTTest(GL)                                        # get differential genes based on t-test\n",
    "        self.diffG=[item for item in self.diffF if item in self.diffT]               # get differnetial genes based on fold change and student t-test\n",
    "       \n",
    "        \n",
    "        self.ptf=self.fromNode.getExpressedTF(dTD.keys(),GL)                         # expressed TFs\n",
    "        self.etf=self.__getetf(dTD,dTG,dMb,GL,fChangeCut)                                       # transcription factors and diff TFs\n",
    "        \n",
    "        #---------------------------------------------------------------------- \n",
    "        self.B=self.__getTransition(dTD,dTG,dMb,GL,fChangeCut)                       # transition offset\n",
    "        self.Q=self.__getProcessVariance(GL,MU=self.fromNode.E)                      # initial process variance\n",
    "          \n",
    "    #--------------------------------------------------------------\n",
    "    # public functons\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # private functions \n",
    "    # calculate fold (log) change between fromNode (cluster) and toNode (cluster)\n",
    "    def __getFC(self,GL):\n",
    "        def logfc(x, y):\n",
    "            return y - x\n",
    "\n",
    "        AE=self.fromNode.E\n",
    "        BE=self.toNode.E\n",
    "        FC=[[abs(logfc(AE[i],BE[i])),logfc(AE[i],BE[i]),i,AE[i],BE[i]] for i in range(len(AE))]\n",
    "\n",
    "        FC.sort(reverse=True)\n",
    "        FC=[[GL[item[2]],item[1],item[3],item[4]] for item in FC]\n",
    "        pdFC=pd.DataFrame(data=FC)\n",
    "        pdFC.columns=['gene','logfc','A','B']\n",
    "        pdFC=pdFC.set_index(['gene'])\n",
    "        return pdFC\n",
    "\n",
    "    # get differential genes between clusters along the path\n",
    "    def __getDiffGene(self,FCUT):\n",
    "        DG=[item for item in self.FC.index if abs(self.FC.loc[item]['logfc'])>FCUT]\n",
    "        return DG\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    # get differential genes between clusters along the path\n",
    "    # using student t-test\n",
    "    def __getDiffGeneTTest(self,GL):\n",
    "        cut=5e-2\n",
    "        TT=[]\n",
    "        for i in range(len(GL)):\n",
    "            X=[item.E[0,i] for item in self.fromNode.cells]\n",
    "            Y=[item.E[0,i] for item in self.toNode.cells]\n",
    "            pxy=ttest_ind(X,Y)[-1]\n",
    "            if pxy<cut:\n",
    "                TT.append([pxy,GL[i]])\n",
    "        TT.sort()\n",
    "        DG=[item[1] for item in TT]\n",
    "        return DG\n",
    "\n",
    "    # # get enriched TFs based on significantly diff genes\n",
    "    #---------------------------------------------------------------\n",
    "    # dMi: input sequence scanning result\n",
    "    # dMb: background sequence scanning result\n",
    "    # n: number of sequences in input\n",
    "    # dTD: dictionary TF->DNA\n",
    "    # dMb: TF binding for background\n",
    "    # review erniched TF\n",
    "\n",
    "    def __getetf(self,dTD,dTG,dMb,GL,FCUT):\n",
    "        # strategy 1 (new): \n",
    "        # using manwhiteneyu test => find TF whose target genes are \"signiciantly\" differential along the edge  (compared with all target genes -background)\n",
    "        def getEnrichTF():\n",
    "            pcut=0.1\n",
    "            K=[item for item in dTD.keys() if item in self.ptf]   # only consider TFs that are expressed in the fromNode (>15% of cells in the node)\n",
    "            BC=[abs(self.FC.loc[item]['logfc']) for item in GL]\n",
    "            entf=[]\n",
    "            for i in K:\n",
    "                iTargets=[item.upper() for item in dTD[i]]\n",
    "                iFC=[abs(self.FC.loc[item]['logfc']) for item in iTargets]\n",
    "                pAB=mannwhitneyu(iFC,BC,alternative=\"greater\")[1]\n",
    "                if pAB<pcut:\n",
    "                    entf.append([pAB,i])\n",
    "            entf=sorted(entf,key=lambda x:x[0])\n",
    "            return entf\n",
    "            \n",
    "        # strategy 2: the target genes of the TF is significiantly overlapping with the DE targets of the edge (used in scdiff1 and out-dated)\n",
    "        def getEnrichTF2():\n",
    "            pcut=0.1\n",
    "            dMi=batchScanPrior([item.upper() for item in self.diffG],dTD)\n",
    "            K=[item for item in dMi.keys() if item in dMb.keys()]\n",
    "            K.sort()\n",
    "            n=len(self.diffG)    # number of diff genes\n",
    "            N=len(GL)            # N: number of sequences in background (all)\n",
    "            entf=[]\n",
    "            for i in K:\n",
    "                Ti=len(dMi[i])\n",
    "                Tb=len(dMb[i])\n",
    "                pr=float(Tb)/N\n",
    "                pvi=1-binom.cdf(Ti-1,n,pr)\n",
    "                if pvi<pcut:\n",
    "                    entf.append([pvi,i])\n",
    "            entf.sort()\n",
    "            return entf\n",
    "        #-------------------------------------------------------------\n",
    "        etf=getEnrichTF()\n",
    "        etf=[item for item in etf if item[1] in self.ptf]\n",
    "        return etf\n",
    "\n",
    "    # Lasso regresion model for each path\n",
    "    def __getTransition(self,dTD,dTG,dMb,GL,FCUT=0.6):\n",
    "        G = self.FC\n",
    "        etfID = [item[1] for item in self.etf]\n",
    "        dR={0:2,1:-2,2:0} \n",
    "        try:\n",
    "            [X, Y,U,D] = buildTrain(G, dTG, etfID,GL,FCUT)\n",
    "            dR = {0: U, 1: D, 2: 0}\n",
    "            LR = LogisticRegressionCV(penalty='l1', Cs=[1.5, 2, 3, 4, 5], solver=\"saga\", multi_class='auto')\n",
    "            LR.fit(X, Y)\n",
    "            CE = LR.coef_\n",
    "            print(\"regression...\")\n",
    "            print(CE)\n",
    "            petf = parseLR(self.etf, CE)\n",
    "            # ---------------------------------------------------------\n",
    "            XX = []\n",
    "            for i in HGL:\n",
    "                if i in dTG:\n",
    "                    tfi = dTG[i]\n",
    "                    xi = [tfi[item] if item in tfi else 0 for item in etfID]\n",
    "                else:\n",
    "                    xi = [0] * len(etfID)\n",
    "                XX.append(xi)\n",
    "            YY = LR.predict(XX)\n",
    "            self.etf = petf\n",
    "        except:\n",
    "            YY = [0 if G.loc[item]['logfc'] > FCUT else 1 if G.loc[item]['logfc'] < -1 * FCUT else 2 for item in GL]\n",
    "        YY = [dR[item] for item in YY]\n",
    "        return YY\n",
    "    \n",
    "    # get process noise \n",
    "    def __getProcessVariance(self,GL,MU=None):\n",
    "        # MU : average at time t-1, vector\n",
    "        # X1: all observation at time point t\n",
    "        # X2:  all observations at time point t\n",
    "       \n",
    "        dim=len(GL)\n",
    "        Q=[]\n",
    "        if MU==None:\n",
    "            for i in range(dim):\n",
    "                x1=[item.E[0,i] for item in self.fromNode.cells] # all observation for gene i at time t-1\n",
    "                mui=sum(x1)/len(x1)+self.B[i]\n",
    "                x2=[item.E[0,i] for item in self.toNode.cells] # all observation for gene i at time t\n",
    "                v=getVarianceVector(x2,mui)\n",
    "                Q.append(v)\n",
    "        else:\n",
    "            for i in range(dim):\n",
    "                x2=[item.E[0,i] for item in self.toNode.cells] # all observation for gene i at time t\n",
    "                mui=MU[i]+self.B[i]\n",
    "                v=getVarianceVector(x2,mui)\n",
    "                Q.append(v)\n",
    "        pcount=0.01\n",
    "        Q=[item+pcount for item in Q]\n",
    "        return Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Class Graph (Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Graph \n",
    "class Graph:\n",
    "    def __init__(self,Cells,tfdna,Clusters,pagaConnects,GL,fChangeCut=0.6,etfile=None):\n",
    "        # native graph attributes\n",
    "        self.Cells=Cells\n",
    "        self.fChangeCut=fChangeCut\n",
    "        self.etfile=etfile\n",
    "        self.GL=GL\n",
    "        self.W=self.getW() # naive  weight for each of the genes \n",
    "        \n",
    "        # nodes \n",
    "        self.Nodes=self.__buildNodes(Clusters)\n",
    "        self.root= self.__guessRoot(pagaConnects) \n",
    "        self.__connectNodes(pagaConnects) # connect the nodes to build the tree\n",
    "        self.getNodePR()\n",
    "        self.__adjustRTFs(self.fChangeCut,self.etfile) # get eTFs for each of hte nodes\n",
    "         \n",
    "        \n",
    "        # edges\n",
    "        [self.dTD,self.dTG,self.dMb]=parseTFDNA(tfdna,GL)\n",
    "        self.Edges=self.__buildEdges()\n",
    "        self.Paths = self.__buildPaths()\n",
    "        \n",
    "        # likelihood \n",
    "        self.llh=self.getLikelihood()\n",
    "        \n",
    "    ##-------------------------------------------------------------------------\n",
    "    # public functions (can be reached outside of the class to update and process the graph)\n",
    "        \n",
    "    # update the graph (tree)\n",
    "    def updateGraph(self,prRes):\n",
    "        print(\"update the graph...\")\n",
    "        \n",
    "        GL=[item.upper() for item in prRes.var.index]\n",
    "        prRes.obs['custom_cluster']=[item.Label for item in self.Cells]\n",
    "        pagaConnects=getPagaConnects(prRes)\n",
    "    \n",
    "        # update nodes\n",
    "        self.Nodes=self.__buildNodes(prRes.obs.custom_cluster)\n",
    "        self.root=self.__guessRoot(pagaConnects)\n",
    "        self.__connectNodes(pagaConnects)\n",
    "        self.__adjustRTFs(GL,self.fChangeCut,self.etfile) \n",
    "        self.getNodePR()\n",
    "        \n",
    "        # update edges\n",
    "        self.Edges=self.__buildEdges()\n",
    "        self.Paths = self.__buildPaths()\n",
    "        \n",
    "    # re-assign the cells (assign new cluster labels to all cells)\n",
    "    def ReAssign(self,ncores):\n",
    "        # re-assign\n",
    "        print(\"re-assigning all cells to the tree\")\n",
    "        \n",
    "        pool=Pool(processes=ncores)\n",
    "        bestA=pool.map(self.AssignCell,self.Cells)\n",
    "        \n",
    "        # update the type Label for each of the cells\n",
    "        for i in range(len(self.Cells)):\n",
    "            bi=bestA[i]\n",
    "            self.Cells[i].Label=self.Nodes[bi].ID\n",
    "            \n",
    "        # update the node cells\n",
    "        for i in self.Nodes:\n",
    "            i.cells=[item for item in self.Cells if item.Label==i.ID]\n",
    "        \n",
    "        newlli=self.getLikelihood()\n",
    "        return newlli\n",
    "        \n",
    "    # assign cell function, private, can only be callced by ReAssign \n",
    "    # this one has to be public (for multi-threading purpose)\n",
    "    def AssignCell(self,cell):\n",
    "        print(\"cell : %s\"%(cell.ID))\n",
    "        pi=[j.getAssignProbability(cell,self.W) for j in self.Nodes]\n",
    "        #print(pi)\n",
    "        bpi=pi.index(max(pi))\n",
    "        return bpi\n",
    "        \n",
    "    \n",
    "    # get the likelihood for the given assignment  (current node cells)\n",
    "    def getLikelihood(self):\n",
    "        Tlli = 0\n",
    "        K=0.01 #  mixture probability constant.\n",
    "        for i in self.Nodes:\n",
    "            pi=[i.getAssignProbability(j,self.W,K) for j in i.cells]\n",
    "            Tlli+=sum(pi)\n",
    "        return Tlli\n",
    "        \n",
    "    \n",
    "    # estimate the prior probability for each cluster (node)\n",
    "    def getNodePR(self):\n",
    "        TotalCells=len(self.Cells)\n",
    "        for i in self.Nodes:\n",
    "            niCells=len(i.cells)\n",
    "            i.PR = niCells*1.0/TotalCells\n",
    "            \n",
    "    # get W (weight for each of the genes)\n",
    "    def getW(self,MW=0.5):\n",
    "        # MW: minimum weight\n",
    "        W = []\n",
    "        pscount=0.1\n",
    "        GL=self.GL\n",
    "        for i in range(len(GL)):\n",
    "            ei = [item.E[0,i] for item in self.Cells]\n",
    "            ei_nonzero = [item for item in ei if item != 0]\n",
    "            wi = float(len(ei_nonzero)+pscount) / (len(ei)+pscount)\n",
    "            W.append(wi)\n",
    "        W=[max(MW,item) for item in W]\n",
    "        return W\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------\n",
    "    # private functions (can only be reached from other functions in the graph calss)\n",
    "    # building the path (from root to the leaves) of the tree\n",
    "    def __buildPaths(self):\n",
    "        print(\"building paths...\")\n",
    "        def getCompletePath(en):\n",
    "            # en: end node\n",
    "            for i in self.Edges:\n",
    "                if i.toNode == en:\n",
    "                    return getCompletePath(i.fromNode) + [i]\n",
    "            return []\n",
    "\n",
    "        CP = []  # complete path\n",
    "        for i in self.Nodes:\n",
    "            if not i.C:\n",
    "                cp =getCompletePath(i)\n",
    "                if cp!=[]:\n",
    "                    CP.append(cp)\n",
    "        #pdb.set_trace()\n",
    "        return CP\n",
    "        \n",
    "    # build edges\n",
    "    def __buildEdges(self):\n",
    "        GL=self.GL\n",
    "        print(\"building edges ...\")\n",
    "        P = []\n",
    "        for i in self.Nodes:\n",
    "            if i.P:\n",
    "                p1 = Path(i.P, i,self.Nodes,GL,self.dTD,self.dTG,self.dMb,self.fChangeCut)\n",
    "                P.append(p1)\n",
    "        return P\n",
    "    \n",
    "    # get eTF (expression based TFs) for each of the nodes \n",
    "    # note, adjustRTF has to stay in Graph class, although it's for each of the nodes\n",
    "    # the inference requires on the complete graph (e.g., parent-children relationships)\n",
    "    # the expresson of the TF must be unique (different to the parent, *and* different to at least one sibling node)\n",
    "    def __adjustRTFs(self,fcut=0.6,tflist=None):\n",
    "        print(\"adjusting RTFs...\")\n",
    "        GL=self.GL\n",
    "        # get RTFs (representating TFs) based on its own expression for each node (the TF expression is different to both parent and siblings)\n",
    "        tflistpath=pkg_resources.resource_filename(__name__,\"tfdata/HumanTFList.txt\") if tflist==None else tflist\n",
    "        try:\n",
    "            with open(tflistpath,'r') as f:\n",
    "                TFs=f.readlines()\n",
    "                TFs=[item.strip().split()[0] for item in TFs]\n",
    "        except:\n",
    "            print(\"error! Please check your input TF List file\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        eTFs=[item for item in [item.upper() for item in GL] if item in TFs]\n",
    "\n",
    "        for Node in self.Nodes:\n",
    "            print(Node.ID)\n",
    "            if Node.P:\n",
    "                NodeParent=Node.P\n",
    "                NodeSib=[item for item in Node.P.C if item!=Node]\n",
    "                NodeSibCells=[] if NodeSib==[] else [item.cells for item in NodeSib]\n",
    "                NodeParentCells=NodeParent.cells\n",
    "                peTFs=[]\n",
    "                for j in eTFs:\n",
    "                    jdex=GL.index(j)\n",
    "                    [flag,pvp,fcp]=tellDifference(Node.cells,NodeParentCells,NodeSibCells,jdex,fcut)\n",
    "                    if flag:\n",
    "                        peTFs.append([pvp,j,fcp])\n",
    "                peTFs.sort()\n",
    "                Node.eTF=peTFs\n",
    "            else:\n",
    "                Node.eTF=[]\n",
    "                \n",
    "    # build nodes\n",
    "    def __buildNodes(self,Clusters):\n",
    "        print(\"building nodes...\")\n",
    "        print(\"start clustering ...\")\n",
    "        \n",
    "        for j in self.Cells:\n",
    "            jID=j.ID\n",
    "            Yj=Clusters[jID]\n",
    "            j.Label=Yj\n",
    "        \n",
    "        ClusterList=list(set(Clusters))\n",
    "        AC=[] # list of all nodes (clusters)\n",
    "        for i in ClusterList:\n",
    "            icells=[item for item in self.Cells if item.Label==i]\n",
    "            CC = Cluster(icells, int(i))\n",
    "            AC.append(CC)\n",
    "        AC=sorted(AC,key=lambda x:x.T)\n",
    "        return AC\n",
    "    \n",
    "    # guess the root node of the tree\n",
    "    def __guessRoot(self,pagaConnects):\n",
    "        self.Nodes=sorted(self.Nodes,key=lambda x:x.T)\n",
    "        return self.Nodes[0]\n",
    "    \n",
    "    \n",
    "    # connect each node (DFS)\n",
    "    def __connectS(self,S,Visited,pagaConnects):\n",
    "        iConnects=pagaConnects.loc[S.ID]+pagaConnects[S.ID]\n",
    "        Visited.append(S.ID)\n",
    "        for j in iConnects.index:\n",
    "            jnode=[item for item in self.Nodes if item.ID==j][0]\n",
    "            if iConnects[j]>0 and (jnode.ID not in Visited):\n",
    "                jnode.P=S\n",
    "                print(\"%s->%s\"%(S.ID,jnode.ID))\n",
    "                self.__connectS(jnode,Visited,pagaConnects)\n",
    "                \n",
    "        \n",
    "    # connect nondes=> infer the parent node for each of the nodes\n",
    "    def __connectNodes(self,pagaConnects):\n",
    "        print(\"connecting nodes ....\")\n",
    "        \n",
    "        # delete old parent-child relationship\n",
    "        for i in self.Nodes:\n",
    "            i.P=None\n",
    "            i.C=[]\n",
    "            \n",
    "        self.__connectS(self.root,[],pagaConnects)\n",
    "            \n",
    "        # infer parents for each of the nodes\n",
    "        \"\"\"\"\n",
    "        nonroot=sorted([item for item in self.Nodes if item!=self.root],key=lambda x:x.T)\n",
    "        allnodes=[self.root]+nonroot\n",
    "        for inode in allnodes:\n",
    "            iConnect=pagaConnects[inode.ID]\n",
    "            for j in iConnect.index:\n",
    "                if(iConnect[j]>0):\n",
    "                    jnode=[item for item in self.Nodes if item.ID==j][0]\n",
    "                    if jnode.T>=inode.T:\n",
    "                        if jnode.P==None:\n",
    "                            jnode.P=inode\n",
    "                    else:\n",
    "                        if inode.P==None:\n",
    "                            inode.P=jnode\n",
    "                            \n",
    "        for inode in allnodes:\n",
    "            if (inode.P==None) and (inode!=self.root):\n",
    "                iConnect=pagaConnects[inode.ID]+pagaConnects.loc[inode.ID]\n",
    "                for j in iConnect.index:\n",
    "                    if iConnect.loc[j]>0:\n",
    "                        jnode=[item for item in self.Nodes if item.ID==j][0]\n",
    "                        if jnode.P!=inode:\n",
    "                            inode.P=jnode\n",
    "                            break \n",
    "        \"\"\"        \n",
    "        # add Children node information\n",
    "        for inode in self.Nodes:\n",
    "            if inode.P!=None:\n",
    "                inode.P.C+=[inode]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the PagaConnects with \n",
    "def getPagaConnects(prRes):\n",
    "    sc.tl.page(prRes,groups='custom_cluster')\n",
    "    pagaConnects=pd.DataFrame(data=prRes.uns['paga']['connectivities_tree'].toarray())\n",
    "    return pageConnects \n",
    "\n",
    "# tell whether the expression is unique in the specified node\n",
    "# 1,-1 (unique, 1: higher, -1: lower), 0 (nonunique)\n",
    "def tellDifference(nodeCells,nodePCells,nodeSibCells,geneIndex,fcut=0.6):\n",
    "    X=[item.E[0,geneIndex] for item in nodeCells]\n",
    "    XP=[item.E[0,geneIndex] for item in nodePCells]\n",
    "    fcp=np.mean(X)-np.mean(XP)\n",
    "    pvp=ranksums(X,XP)[1]\n",
    "    pcut=0.05\n",
    "    \n",
    "    # if no sibling nodes\n",
    "    if len(nodeSibCells)==0:\n",
    "        if (pvp<pcut) and (fcp>fcut or fcp<-1*fcut):\n",
    "            return [1,pvp,fcp]\n",
    "    \n",
    "    # if has sibling nodes\n",
    "    for sNodeCells in nodeSibCells:\n",
    "        Y=[item.E[0,geneIndex] for item in sNodeCells]\n",
    "        fcs=np.mean(X)-np.mean(Y)\n",
    "        pvs=ranksums(X,Y)[1]\n",
    "        if (pvp<pcut and pvs<pcut) and ((fcp>fcut and fcs>fcut) or (fcp<-1*fcut and fcs<-1*fcut)):\n",
    "            return [1,pvp,fcp]\n",
    "        \n",
    "    return [0,pvp,fcp]\n",
    "\n",
    "    # get variance for the input vector x\n",
    "def getVarianceVector(x,mu=None):\n",
    "    # x:the observation of one gene at specific time t\n",
    "    if mu==None:\n",
    "            mu=float(sum(x))/len(x)\n",
    "    v=[(item-mu)**2 for item in x]\n",
    "    v=sum(v)*1.0/len(x)\n",
    "    return v\n",
    "\n",
    "# parse input tfdna file\n",
    "def parseTFDNA(tfdna,GL):\n",
    "    RTD=TabFile(tfdna).read('\\t') # dictionary to store the TF-DNA info\n",
    "    DEFAULTACTIVITY=1.0\n",
    "    try:\n",
    "        if len(RTD[0])==2:\n",
    "            TD=[[item[0].upper(),item[1].upper(),DEFAULTACTIVITY] for item in RTD[1:] if len(item)>1]\n",
    "        elif len(RTD[0])==3:\n",
    "            TD=[[item[0].upper(),item[1].upper(),float(item[2])] for item in RTD[1:] if len(item)>2]\n",
    "        else:\n",
    "            TFs=RTD[0][1:]\n",
    "            genes=[item[0] for item in RTD[1:]]\n",
    "            RTDM=[[float(k) for k in item[1:]] for item in RTD[1:]]\n",
    "            TD=[]\n",
    "            for i in range(len(genes)):\n",
    "                for j in range(len(TFs)):\n",
    "                    TD.append([TFs[j],genes[i],RTDM[i][j]])\n",
    "    except:\n",
    "        print(\"check the format of input TF-DNA interaction file\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    [dTD,dTG]=getTFDNAInteraction(TD,GL)\n",
    "    # TF binding in all input sequences (background)\n",
    "    dMb=batchScanPrior(GL,dTD)\n",
    "    return [dTD,dTG,dMb]\n",
    "\n",
    "\n",
    "# scanning TF-DNA interaction prior\n",
    "def batchScanPrior(A,dTD):\n",
    "    # dTD  -> dictionary of TF-DNA interaction\n",
    "    # A -> Gene list\n",
    "    K=list(dTD.keys())\n",
    "    K.sort()\n",
    "    dM={}\n",
    "    dA={item:0 for item in A}\n",
    "    for i in K:\n",
    "        GI=dTD[i]\n",
    "        GI=list(set([item for item in GI if item in dA]))\n",
    "        if len(GI)>0:\n",
    "            dM[i]=GI\n",
    "    return dM\n",
    "\n",
    "# get TF-Gene interactions\n",
    "def getTFDNAInteraction(TD,GL):\n",
    "    dTD = {}  # TF->DNA\n",
    "    dTG = {}  # DNA->TF\n",
    "    for i in TD:\n",
    "        if i[2]>0 and i[1].upper() in GL:\n",
    "            if i[0] not in dTD:\n",
    "                dTD[i[0]] = [i[1]]\n",
    "            else:\n",
    "                \n",
    "                dTD[i[0]].append(i[1])\n",
    "\n",
    "            if i[1] not in dTG:\n",
    "                dTG[i[1]] = {}\n",
    "                dTG[i[1]][i[0]] = i[2]\n",
    "            else:\n",
    "                dTG[i[1]][i[0]] = i[2]\n",
    "    return [dTD,dTG]\n",
    "\n",
    "# building traning dataset for regression\n",
    "def buildTrain(G,dTG,ptf,GL,Fcut=1):\n",
    "    # G: differential genes for a given path\n",
    "    # dTD: DNA->TF dictionary\n",
    "    # TF candidate\n",
    "    Ncut=Fcut/2.0\n",
    "    UP=[item for item in G if item[1]>Fcut]\n",
    "    DN=[item for item in G if item[1]<-1*Fcut]\n",
    "    NN=[item for item in G if abs(item[1])<Ncut]\n",
    "\n",
    "\n",
    "    U=sum([item[1] for item in UP])/len(UP)\n",
    "    D=sum([item[1] for item in DN])/len(DN)\n",
    "\n",
    "    UP=[item[0].upper() for item in UP]\n",
    "    DN=[item[0].upper() for item in DN]\n",
    "    NN=[item[0].upper() for item in NN]\n",
    "\n",
    "\n",
    "    XU=[]\n",
    "    XD=[]\n",
    "    XN=[]\n",
    "\n",
    "    YU=[]\n",
    "    YD=[]\n",
    "    YN=[]\n",
    "\n",
    "    HGL=[item.upper() for item in GL]\n",
    "    for i in HGL:\n",
    "        if i in dTG:\n",
    "            tfi=dTG[i]\n",
    "            xi=[tfi[item] if item in tfi else 0 for item in ptf]\n",
    "            if i in UP:\n",
    "                yi=0\n",
    "                XU.append(xi)\n",
    "                YU.append(yi)\n",
    "            elif i in DN:\n",
    "                yi=1\n",
    "                XD.append(xi)\n",
    "                YD.append(yi)\n",
    "            elif i in NN:\n",
    "                yi=2\n",
    "                XN.append(xi)\n",
    "                YN.append(yi)\n",
    "\n",
    "    X=XU+XD+XN\n",
    "    Y=YU+YD+YN\n",
    "    \n",
    "    # to solve the imbalanced training set issue, use over-sampling techqniue- SMOTE\n",
    "    sm=SMOTE(random_state=0)\n",
    "    Xs,Ys=sm.fit_sample(X,Y)\n",
    "\n",
    "    Xs=list(Xs)\n",
    "    Ys=list(Ys)\n",
    "\n",
    "    return [Xs,Ys,U,D]\n",
    "\n",
    "# parse Logistic regression result\n",
    "def parseLR(etf,LRC):\n",
    "    LRC=[max(item) for item in LRC.T]\n",
    "    out_etf=[]\n",
    "    for i in range(len(LRC)):\n",
    "        if LRC[i]>0:\n",
    "            out_etf.append(etf[i]+[LRC[i]])\n",
    "    return out_etf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # parse input arguments\n",
    "    parser=argparse.ArgumentParser(description=\"scdiff2 main\")\n",
    "    parser.add_argument('-i','--input',required=True,help='h5ad result from pre-run')\n",
    "    parser.add_argument('-o','--output',required=True,help='output directory')\n",
    "    parser.add_argument('-t','--tfdna',required=True, help='TF-DNA interaction data')\n",
    "    parser.add_argument('--etfListFile',required=False,help='By default, this program recognizes 1.6k TFs (collected in human and mouse). Users are able \\\n",
    "                                                            to provide a customized list of TFsã€€using this option (e.g, for another species).')                                                       \n",
    "    parser.add_argument('--log2fc',required=False,default=0.6, help='By default, scdiff uses log2 Fold change 0.6(=>2^0.6~=1.5) as the cutoff \\\n",
    "                                                            for differential genes (together with wilcoxon test p-value cutoff 0.05). \\\n",
    "                                                            However, users can customize this log fold change cutoff.')\n",
    "    parser.add_argument('--ncores',required=False,default=4, help='# of allocated cpu cores for the job (4 by default)')\n",
    "    parser.add_argument('--root',required=False,default=None, help='set root (of the tree) as input cluster ID (from pre-run result)')  \n",
    "    parser.add_argument('--llhCut',required=False,default=0.01, help='The convergence likelihood cutoff, the program stops if the cell \\\n",
    "                                                            assignment likelihood improvement is smaller than this cutoff (e.g. 0.01->1%)') \n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    # input arguments\n",
    "    scg=args.input\n",
    "    output=args.output\n",
    "    tfdna=args.tfdna\n",
    "    tfList=args.etfListFile\n",
    "    fChangeCut=float(args.log2fc)\n",
    "    ncores=int(args.ncores)\n",
    "    rootNode=args.root\n",
    "    llhcut=float(args.llhCut)\n",
    "                        \n",
    "    '''\n",
    "    scg=\"t1_out/example.E.h5ad\"\n",
    "    output=\"t1_out\"\n",
    "    tfdna=\"tfdata/example.tf_dna\"\n",
    "    tfList=\"tfdata/HumanTFList.txt\"\n",
    "    fChangeCut=0.6\n",
    "    ncores=10 # number of cores used\n",
    "    rootNode=None\n",
    "    llhcut=0.01 # stop if the likelihood inprovement is less than 1%\n",
    "    '''\n",
    "                        \n",
    "    #Read in the prerun results from the prerun (in h5ad format)\n",
    "    print(\"loading back prerun results (h5ad) ...\")\n",
    "    prRes=anndata.read_h5ad(scg)\n",
    "    \n",
    "    #Convert full matrix to sparse_matrix to reduce the memory usage\n",
    "    # Expression matrix (sparse)\n",
    "    prRes.X=csr_matrix(prRes.X)\n",
    "\n",
    "    # Genes\n",
    "    GL=[item.upper() for item in prRes.var.index]\n",
    "\n",
    "    # clusters\n",
    "    clusters=prRes.obs.leiden\n",
    "\n",
    "    # paga connectivity\n",
    "    pagaConnects=pd.DataFrame(data=prRes.uns['paga']['connectivities_tree'].toarray())\n",
    "    \n",
    "    print(\"reading cells ...\")\n",
    "    \n",
    "    # list to store all cells\n",
    "    AllCells=[]\n",
    "    \n",
    "    for i in range(len(prRes.obs.index)):\n",
    "        iid=prRes.obs.index[i]\n",
    "        ti=float(prRes.obs.time[i])\n",
    "        li=prRes.obs.label[i]\n",
    "        ei=prRes.X[i,:]\n",
    "        ci=Cell(iid,ti,ei,li)\n",
    "        AllCells.append(ci)\n",
    "        print('cell: '+str(i))\n",
    "        \n",
    "    print(\"clustering cells ...\")\n",
    "    \n",
    "    #load clusters from the prerun results\n",
    "    clusters=prRes.obs.leiden\n",
    "    \n",
    "    print(\"building graph (tree)...\")\n",
    "    \n",
    "    G1=Graph(AllCells,tfdna,clusters,pagaConnects,GL,fChangeCut,etfile=None)\n",
    "    \n",
    "    #drawing graphs\n",
    "    if os.path.exists(output)==False:\n",
    "        os.mkdir(output)\n",
    "\n",
    "    scg_name=scg.split('/')[-1]\n",
    "    \n",
    "    # writing out Graph...\n",
    "    viz(scg_name,G1,output,prRes)\n",
    "    \n",
    "    ollh=G1.llh # old likelihood\n",
    "    print(\"likelihood: %s\"%(ollh))\n",
    "    \n",
    "    MAXLOOP=6 # Max Loops\n",
    "    \n",
    "    for loop in range(MAXLOOP):\n",
    "        print(loop)\n",
    "        nllh=G1.ReAssign(ncores)\n",
    "        increase_llh=(nllh-ollh)/abs(ollh)\n",
    "        print(\"likelihood: %s\"%(nllh))\n",
    "        if increase_llh<llhcut:\n",
    "            break \n",
    "        G1.updateGraph(prRes)\n",
    "    print(\"job completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading back prerun results (h5ad) ...\n",
      "reading cells ...\n",
      "cell: 0\n",
      "cell: 1\n",
      "cell: 2\n",
      "cell: 3\n",
      "cell: 4\n",
      "cell: 5\n",
      "cell: 6\n",
      "cell: 7\n",
      "cell: 8\n",
      "cell: 9\n",
      "cell: 10\n",
      "cell: 11\n",
      "cell: 12\n",
      "cell: 13\n",
      "cell: 14\n",
      "cell: 15\n",
      "cell: 16\n",
      "cell: 17\n",
      "cell: 18\n",
      "cell: 19\n",
      "cell: 20\n",
      "cell: 21\n",
      "cell: 22\n",
      "cell: 23\n",
      "cell: 24\n",
      "cell: 25\n",
      "cell: 26\n",
      "cell: 27\n",
      "cell: 28\n",
      "cell: 29\n",
      "cell: 30\n",
      "cell: 31\n",
      "cell: 32\n",
      "cell: 33\n",
      "cell: 34\n",
      "cell: 35\n",
      "cell: 36\n",
      "cell: 37\n",
      "cell: 38\n",
      "cell: 39\n",
      "cell: 40\n",
      "cell: 41\n",
      "cell: 42\n",
      "cell: 43\n",
      "cell: 44\n",
      "cell: 45\n",
      "cell: 46\n",
      "cell: 47\n",
      "cell: 48\n",
      "cell: 49\n",
      "cell: 50\n",
      "cell: 51\n",
      "cell: 52\n",
      "cell: 53\n",
      "cell: 54\n",
      "cell: 55\n",
      "cell: 56\n",
      "cell: 57\n",
      "cell: 58\n",
      "cell: 59\n",
      "cell: 60\n",
      "cell: 61\n",
      "cell: 62\n",
      "cell: 63\n",
      "cell: 64\n",
      "cell: 65\n",
      "cell: 66\n",
      "cell: 67\n",
      "cell: 68\n",
      "cell: 69\n",
      "cell: 70\n",
      "cell: 71\n",
      "cell: 72\n",
      "cell: 73\n",
      "cell: 74\n",
      "cell: 75\n",
      "cell: 76\n",
      "cell: 77\n",
      "cell: 78\n",
      "cell: 79\n",
      "cell: 80\n",
      "cell: 81\n",
      "cell: 82\n",
      "cell: 83\n",
      "cell: 84\n",
      "cell: 85\n",
      "cell: 86\n",
      "cell: 87\n",
      "cell: 88\n",
      "cell: 89\n",
      "cell: 90\n",
      "cell: 91\n",
      "cell: 92\n",
      "cell: 93\n",
      "cell: 94\n",
      "cell: 95\n",
      "cell: 96\n",
      "cell: 97\n",
      "cell: 98\n",
      "cell: 99\n",
      "cell: 100\n",
      "cell: 101\n",
      "cell: 102\n",
      "cell: 103\n",
      "cell: 104\n",
      "cell: 105\n",
      "cell: 106\n",
      "cell: 107\n",
      "cell: 108\n",
      "cell: 109\n",
      "cell: 110\n",
      "cell: 111\n",
      "cell: 112\n",
      "cell: 113\n",
      "cell: 114\n",
      "cell: 115\n",
      "cell: 116\n",
      "cell: 117\n",
      "cell: 118\n",
      "cell: 119\n",
      "cell: 120\n",
      "cell: 121\n",
      "cell: 122\n",
      "cell: 123\n",
      "cell: 124\n",
      "cell: 125\n",
      "cell: 126\n",
      "cell: 127\n",
      "cell: 128\n",
      "cell: 129\n",
      "cell: 130\n",
      "cell: 131\n",
      "cell: 132\n",
      "cell: 133\n",
      "cell: 134\n",
      "cell: 135\n",
      "cell: 136\n",
      "cell: 137\n",
      "cell: 138\n",
      "cell: 139\n",
      "cell: 140\n",
      "cell: 141\n",
      "cell: 142\n",
      "cell: 143\n",
      "cell: 144\n",
      "cell: 145\n",
      "cell: 146\n",
      "cell: 147\n",
      "cell: 148\n",
      "cell: 149\n",
      "cell: 150\n",
      "cell: 151\n",
      "clustering cells ...\n",
      "building graph (tree)...\n",
      "building nodes...\n",
      "start clustering ...\n",
      "connecting nodes ....\n",
      "1->2\n",
      "1->3\n",
      "1->4\n",
      "4->0\n",
      "adjusting RTFs...\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "building edges ...\n",
      "building paths...\n",
      "writing out Graph ...\n",
      "Dimension reduction ...\n",
      "PCA ...\n",
      "tnse...\n",
      "diffusion map...\n",
      "creating json file ...\n",
      "likelihood: -1244.2461712287786\n",
      "0\n",
      "re-assigning all cells to the tree\n",
      "cell : E14_1_C44\n",
      "cell : E14_1_C90\n",
      "cell : E14_1_C10\n",
      "cell : E14_1_C75\n",
      "cell : E14_1_C78\n",
      "cell : E14_1_C83\n",
      "cell : E14_1_C39\n",
      "cell : E14_1_C09\n",
      "cell : E14_1_C05\n",
      "cell : E14_1_C77\n",
      "cell : E14_1_C68\n",
      "cell : E14_1_C01\n",
      "cell : E14_1_C06\n",
      "cell : E14_1_C16\n",
      "cell : E14_1_C74\n",
      "cell : E14_1_C95\n",
      "cell : E14_1_C02\n",
      "cell : E14_1_C46\n",
      "cell : E14_1_C18\n",
      "cell : E14_1_C81\n",
      "cell : E14_1_C84\n",
      "cell : E14_1_C69\n",
      "cell : E14_1_C25\n",
      "cell : E14_1_C31\n",
      "cell : E14_1_C14\n",
      "cell : E14_1_C65\n",
      "cell : E14_1_C85\n",
      "cell : E14_1_C60\n",
      "cell : E14_1_C73\n",
      "cell : E14_1_C87\n",
      "cell : E14_1_C70\n",
      "cell : E14_1_C89\n",
      "cell : E14_1_C51\n",
      "cell : E14_1_C76\n",
      "cell : E14_1_C50\n",
      "cell : E14_1_C94\n",
      "cell : E14_1_C54\n",
      "cell : E14_1_C22\n",
      "cell : E14_1_C57\n",
      "cell : E14_1_C61\n",
      "cell : E14_1_C79\n",
      "cell : E14_1_C80\n",
      "cell : E16_1_C83\n",
      "cell : E16_1_C72\n",
      "cell : E16_1_C06\n",
      "cell : E16_1_C66\n",
      "cell : E16_1_C67\n",
      "cell : E16_1_C88\n",
      "cell : E18_2_C73\n",
      "cell : E18_1_C62\n",
      "cell : E16_1_C90\n",
      "cell : E14_1_C66\n",
      "cell : E16_1_C14\n",
      "cell : E16_1_C94\n",
      "cell : E16_1_C86\n",
      "cell : E16_1_C54\n",
      "cell : E16_1_C95\n",
      "cell : E18_2_C69\n",
      "cell : E16_1_C49\n",
      "cell : E18_2_C88\n",
      "cell : E14_1_C96\n",
      "cell : E16_1_C15\n",
      "cell : E16_1_C01\n",
      "cell : E16_1_C40\n",
      "cell : E16_1_C68\n",
      "cell : E16_1_C24\n",
      "cell : E16_1_C31\n",
      "cell : E16_1_C74\n",
      "cell : E18_1_C18\n",
      "cell : E18_3_C90\n",
      "cell : E16_1_C04\n",
      "cell : E14_1_C56\n",
      "cell : E16_1_C65\n",
      "cell : E16_1_C56\n",
      "cell : E16_1_C57\n",
      "cell : E16_1_C92\n",
      "cell : E16_1_C84\n",
      "cell : E16_1_C05\n",
      "cell : E18_2_C55\n",
      "cell : E18_1_C15\n",
      "cell : E18_1_C84\n",
      "cell : E18_2_C87\n",
      "cell : E18_3_C40\n",
      "cell : E18_2_C22\n",
      "cell : E18_1_C38\n",
      "cell : E18_3_C51\n",
      "cell : E18_1_C37\n",
      "cell : E18_2_C63\n",
      "cell : E18_3_C87\n",
      "cell : E18_1_C53\n",
      "cell : E18_3_C37\n",
      "cell : E18_3_C61\n",
      "cell : E18_3_C54\n",
      "cell : E18_2_C72\n",
      "cell : E18_2_C15\n",
      "cell : E18_1_C67\n",
      "cell : E18_3_C53\n",
      "cell : E18_3_C06\n",
      "cell : E18_3_C75\n",
      "cell : E18_2_C30\n",
      "cell : E18_2_C77\n",
      "cell : E18_2_C42\n",
      "cell : E18_3_C80\n",
      "cell : E18_1_C34\n",
      "cell : E18_2_C49\n",
      "cell : E18_3_C10\n",
      "cell : E18_3_C59\n",
      "cell : E18_1_C45\n",
      "cell : E18_2_C26\n",
      "cell : E18_1_C09\n",
      "cell : E18_2_C43\n",
      "cell : E18_1_C47\n",
      "cell : E18_3_C09\n",
      "cell : E18_3_C82\n",
      "cell : E18_2_C65\n",
      "cell : E18_1_C50\n",
      "cell : E18_2_C44\n",
      "cell : E18_2_C12\n",
      "cell : E18_1_C33\n",
      "cell : E18_3_C29\n",
      "cell : E18_2_C36\n",
      "cell : E18_2_C50\n",
      "cell : E18_3_C41\n",
      "cell : E18_3_C13\n",
      "cell : E18_1_C11\n",
      "cell : E18_1_C13\n",
      "cell : E18_2_C59\n",
      "cell : E18_2_C38\n",
      "cell : E18_2_C31\n",
      "cell : E18_3_C15\n",
      "cell : E18_3_C28\n",
      "cell : E18_2_C13\n",
      "cell : E18_1_C60\n",
      "cell : E18_2_C74\n",
      "cell : E18_1_C44\n",
      "cell : E18_1_C46\n",
      "cell : E18_3_C36\n",
      "cell : E18_3_C23\n",
      "cell : E18_2_C61\n",
      "cell : E18_2_C81\n",
      "cell : E18_2_C32\n",
      "cell : E18_3_C47\n",
      "cell : E18_2_C11\n",
      "cell : E18_3_C55\n",
      "cell : E18_2_C06\n",
      "cell : E18_1_C08\n",
      "cell : E18_3_C26\n",
      "cell : E18_3_C48\n",
      "cell : E18_2_C92\n",
      "cell : E18_2_C20\n",
      "cell : E18_2_C07\n",
      "cell : E18_2_C90\n",
      "likelihood: -1244.2461713649298\n",
      "job completed!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
